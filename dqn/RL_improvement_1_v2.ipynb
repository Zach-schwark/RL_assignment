{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zwFHr-K6O5t",
        "outputId": "89605730-ee04-4f66-c4c7-0b2963782c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting Grid2Op\n",
            "  Downloading Grid2Op-1.10.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightsim2grid\n",
            "  Downloading LightSim2Grid-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.3)\n",
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-2.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from Grid2Op) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from Grid2Op) (2.2.2)\n",
            "Collecting pandapower>=2.2.2 (from Grid2Op)\n",
            "  Downloading pandapower-2.14.11.zip (13.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.10/dist-packages (from Grid2Op) (4.66.5)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from Grid2Op) (3.4.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from Grid2Op) (2.32.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Grid2Op) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightsim2grid) (75.1.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from lightsim2grid) (24.1.2)\n",
            "Collecting pybind11 (from lightsim2grid)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.16.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.4.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.17.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.9.2)\n",
            "Collecting shimmy~=1.3.0 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra])\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (10.4.0)\n",
            "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Collecting deepdiff (from pandapower>=2.2.2->Grid2Op)\n",
            "  Downloading deepdiff-8.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->Grid2Op) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->Grid2Op) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->Grid2Op) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->Grid2Op) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->Grid2Op) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->Grid2Op) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->Grid2Op) (2024.8.30)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (6.4.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.1)\n",
            "Collecting orderly-set==5.2.2 (from deepdiff->pandapower>=2.2.2->Grid2Op)\n",
            "  Downloading orderly_set-5.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Downloading Grid2Op-1.10.5-py3-none-any.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading LightSim2Grid-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (853 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.8/853.8 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sb3_contrib-2.3.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: pandapower, AutoROM.accept-rom-license\n",
            "  Building wheel for pandapower (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandapower: filename=pandapower-2.14.11-py3-none-any.whl size=13131028 sha256=b9d455e7e11c555d6e6aa8bc6b37fd147849535084ba2777d889aad619fa85b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/de/5a/7b00f385eb06d1fb1f7c1cd06f9bb901709c038d3899548cf1\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=62b980d830c440a38bc33b4ba6b80885426503ed54109b4d51bfb54b0c9915ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built pandapower AutoROM.accept-rom-license\n",
            "Installing collected packages: farama-notifications, pybind11, orderly-set, gymnasium, ale-py, shimmy, lightsim2grid, deepdiff, AutoROM.accept-rom-license, autorom, stable-baselines3, pandapower, sb3-contrib, Grid2Op\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 Grid2Op-1.10.5 ale-py-0.8.1 autorom-0.6.1 deepdiff-8.0.1 farama-notifications-0.0.4 gymnasium-0.29.1 lightsim2grid-0.9.2 orderly-set-5.2.2 pandapower-2.14.11 pybind11-2.13.6 sb3-contrib-2.3.0 shimmy-1.3.0 stable-baselines3-2.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium Grid2Op lightsim2grid wandb stable-baselines3[extra] sb3-contrib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_array = [\n",
        "    'a_ex', 'a_or', 'active_alert', 'actual_dispatch', 'alert_duration', 'attack_under_alert',\n",
        "    'attention_budget', 'current_step', 'curtailment', 'curtailment_limit',\n",
        "    'curtailment_limit_effective', 'curtailment_limit_mw', 'curtailment_mw', 'day',\n",
        "    'day_of_week', 'delta_time', 'duration_next_maintenance', 'gen_margin_down',\n",
        "    'gen_margin_up', 'gen_p', 'gen_p_before_curtail', 'gen_q', 'gen_theta', 'gen_v',\n",
        "    'hour_of_day', 'is_alarm_illegal', 'last_alarm', 'line_status', 'load_p', 'load_q',\n",
        "    'load_theta', 'load_v', 'max_step', 'minute_of_hour', 'month', 'p_ex', 'p_or',\n",
        "    'prod_p', 'prod_q', 'prod_v', 'q_ex', 'q_or', 'rho', 'storage_charge',\n",
        "    'storage_power', 'storage_power_target', 'storage_theta', 'target_dispatch',\n",
        "    'thermal_limit', 'theta_ex', 'theta_or', 'time_before_cooldown_line',\n",
        "    'time_before_cooldown_sub', 'time_next_maintenance', 'time_since_last_alarm',\n",
        "    'time_since_last_alert', 'time_since_last_attack', 'timestep_overflow', 'topo_vect',\n",
        "    'total_number_of_alert', 'v_ex', 'v_or', 'was_alarm_used_after_game_over',\n",
        "    'was_alert_used_after_attack', 'year'\n",
        "]\n",
        "\n",
        "attr_to_keep_3 = ['a_ex', 'a_or', 'active_alert', 'actual_dispatch', 'alert_duration',\n",
        "    'attention_budget', 'current_step','curtailment', 'curtailment_limit', 'curtailment_limit_effective', 'curtailment_limit_mw', 'curtailment_mw','day',\n",
        "    'day_of_week', 'delta_time', 'duration_next_maintenance', 'gen_margin_down',\n",
        "    'gen_margin_up', 'gen_p', 'gen_p_before_curtail', 'gen_q', 'gen_theta', 'gen_v',\n",
        "    'hour_of_day', 'last_alarm', 'line_status', 'load_p', 'load_q',\n",
        "    'load_theta', 'load_v', 'max_step', 'minute_of_hour', 'month', 'p_ex', 'p_or',\n",
        "    'prod_p', 'prod_q', 'prod_v', 'q_ex', 'q_or', 'rho', 'storage_charge',\n",
        "    'storage_power', 'storage_power_target', 'storage_theta', 'target_dispatch',\n",
        "    'thermal_limit', 'theta_ex', 'theta_or', 'time_before_cooldown_line',\n",
        "    'time_before_cooldown_sub', 'time_next_maintenance',\n",
        "    'timestep_overflow', 'topo_vect','v_ex', 'v_or',\n",
        "     'year']#so far the best\n",
        "\n",
        "attr_to_keep_4 = ['a_ex', 'a_or',  'actual_dispatch',\n",
        "    'attention_budget', 'current_step','curtailment', 'curtailment_limit', 'curtailment_limit_effective', 'curtailment_limit_mw', 'curtailment_mw','day',\n",
        "    'day_of_week', 'delta_time', 'duration_next_maintenance', 'gen_margin_down',\n",
        "    'gen_margin_up', 'gen_p', 'gen_p_before_curtail', 'gen_q', 'gen_theta', 'gen_v',\n",
        "    'hour_of_day', 'line_status', 'load_p', 'load_q',\n",
        "    'load_theta', 'load_v', 'max_step', 'minute_of_hour', 'month', 'p_ex', 'p_or',\n",
        "    'prod_p', 'prod_q', 'prod_v', 'q_ex', 'q_or', 'rho', 'storage_charge',\n",
        "    'storage_power', 'storage_power_target', 'storage_theta', 'target_dispatch',\n",
        "    'thermal_limit', 'theta_ex', 'theta_or', 'time_before_cooldown_line',\n",
        "    'time_before_cooldown_sub', 'time_next_maintenance',\n",
        "    'timestep_overflow', 'topo_vect','v_ex', 'v_or',\n",
        "     'year'] #this one is bad so active alert and alert duration is important\n",
        "\n",
        "attr_to_keep_5 = ['a_ex', 'a_or', 'active_alert', 'actual_dispatch', 'alert_duration',\n",
        "    'attention_budget', 'current_step','curtailment', 'curtailment_limit', 'curtailment_limit_effective', 'curtailment_limit_mw', 'curtailment_mw','day',\n",
        "    'day_of_week', 'delta_time', 'duration_next_maintenance', 'gen_margin_down',\n",
        "    'gen_margin_up', 'gen_p', 'gen_p_before_curtail', 'gen_q', 'gen_theta', 'gen_v',\n",
        "    'hour_of_day', 'last_alarm', 'line_status', 'load_p', 'load_q',\n",
        "    'load_theta', 'load_v', 'max_step', 'minute_of_hour', 'month', 'p_ex', 'p_or',\n",
        "    'prod_p', 'prod_q', 'prod_v', 'q_ex', 'q_or', 'rho',\n",
        "    'storage_power', 'storage_power_target', 'storage_theta', 'target_dispatch',\n",
        "    'thermal_limit', 'theta_ex', 'theta_or', 'time_before_cooldown_line',\n",
        "    'time_before_cooldown_sub', 'time_next_maintenance',\n",
        "    'timestep_overflow', 'topo_vect','v_ex', 'v_or',\n",
        "     'year'] #removed storage charged - does very bad\n",
        "\n",
        "attr_to_keep_6 = ['a_ex', 'a_or', 'active_alert', 'actual_dispatch', 'alert_duration',\n",
        "    'attention_budget', 'current_step','curtailment', 'curtailment_limit', 'curtailment_limit_effective', 'curtailment_limit_mw', 'curtailment_mw','day',\n",
        "    'day_of_week', 'delta_time', 'duration_next_maintenance', 'gen_margin_down',\n",
        "    'gen_margin_up', 'gen_p', 'gen_p_before_curtail', 'gen_q', 'gen_theta', 'gen_v',\n",
        "    'hour_of_day', 'last_alarm', 'line_status', 'load_p', 'load_q',\n",
        "    'load_theta', 'load_v', 'max_step', 'minute_of_hour', 'month', 'p_ex', 'p_or',\n",
        "    'prod_p', 'prod_q', 'prod_v', 'q_ex', 'q_or', 'rho', 'storage_charge',\n",
        "    'storage_power', 'storage_power_target', 'storage_theta', 'target_dispatch',\n",
        "    'thermal_limit', 'theta_ex', 'theta_or', 'time_before_cooldown_line',\n",
        "     'time_next_maintenance',\n",
        "    'timestep_overflow', 'topo_vect','v_ex', 'v_or',\n",
        "     'year']#'time_before_cooldown_sub'\n",
        "\n",
        "attr_to_keep = [\"rho\", \"gen_p\", \"load_p\", \"topo_vect\", \"actual_dispatch\"]\n"
      ],
      "metadata": {
        "id": "IkkbJIIa6agB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import Discrete, MultiDiscrete, Box\n",
        "\n",
        "import grid2op\n",
        "from grid2op import gym_compat\n",
        "from grid2op.Parameters import Parameters\n",
        "from grid2op.Action import PlayableAction\n",
        "from grid2op.Observation import CompleteObservation\n",
        "from grid2op.Reward import L2RPNReward, N1Reward, CombinedScaledReward\n",
        "from grid2op.gym_compat import DiscreteActSpace, BoxGymObsSpace\n",
        "\n",
        "from lightsim2grid import LightSimBackend\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Gymnasium environment wrapper around Grid2Op environment\n",
        "class Gym2OpEnv(gym.Env):\n",
        "    def __init__(self, attr_to_keep):\n",
        "        super().__init__()\n",
        "\n",
        "        self._backend = LightSimBackend()\n",
        "        self._env_name = \"l2rpn_case14_sandbox\"  # DO NOT CHANGE\n",
        "\n",
        "        action_class = PlayableAction\n",
        "        observation_class = CompleteObservation\n",
        "        reward_class = CombinedScaledReward  # Setup further below\n",
        "\n",
        "        # DO NOT CHANGE Parameters\n",
        "        # See https://grid2op.readthedocs.io/en/latest/parameters.html\n",
        "        p = Parameters()\n",
        "        p.MAX_SUB_CHANGED = 4  # Up to 4 substations can be reconfigured each timestep\n",
        "        p.MAX_LINE_STATUS_CHANGED = 4  # Up to 4 powerline statuses can be changed each timestep\n",
        "\n",
        "        # Make grid2op env\n",
        "        self._g2op_env = grid2op.make(\n",
        "            self._env_name, backend=self._backend, test=False,\n",
        "            action_class=action_class, observation_class=observation_class,\n",
        "            reward_class=reward_class, param=p\n",
        "        )\n",
        "\n",
        "        ##########\n",
        "        # REWARD #\n",
        "        ##########\n",
        "        # NOTE: This reward should not be modified when evaluating RL agent\n",
        "        # See https://grid2op.readthedocs.io/en/latest/reward.html\n",
        "        cr = self._g2op_env.get_reward_instance()\n",
        "        cr.addReward(\"N1\", N1Reward(), 1.0)\n",
        "        cr.addReward(\"L2RPN\", L2RPNReward(), 1.0)\n",
        "        # reward = N1 + L2RPN\n",
        "        cr.initialize(self._g2op_env)\n",
        "        ##########\n",
        "\n",
        "        self._gym_env = gym_compat.GymEnv(self._g2op_env)\n",
        "\n",
        "        self.setup_observations()\n",
        "        self.setup_actions()\n",
        "\n",
        "        self.observation_space = self._gym_env.observation_space\n",
        "        self.action_space = self._gym_env.action_space\n",
        "        self.attr_to_keep = attr_to_keep\n",
        "\n",
        "    # The information i used to get the code for the below 2 functions is fromm the getting started from the Grid2Op github.\n",
        "    # specifcally theis link was useful at helping change the observation and action spaces to use with gymnasium : https://github.com/rte-france/Grid2Op/blob/c71a2dfb824dae7115394266e02cc673c8633a0e/getting_started/11_IntegrationWithExistingRLFrameworks.ipynb\n",
        "    # these links also help explain the observation and action space:\n",
        "        # https://github.com/rte-france/Grid2Op/blob/c71a2dfb824dae7115394266e02cc673c8633a0e/getting_started/02_Observation.ipynb\n",
        "        # https://github.com/rte-france/Grid2Op/blob/c71a2dfb824dae7115394266e02cc673c8633a0e/getting_started/03_Action.ipynb\n",
        "\n",
        "    def setup_observations(self):\n",
        "        # TODO: Your code to specify & modify the observation space goes here\n",
        "        # See Grid2Op 'getting started' notebooks for guidance\n",
        "        #  - Notebooks: https://github.com/rte-france/Grid2Op/tree/master/getting_started\n",
        "\n",
        "        # The code below is simple code too make the Grid2Op observation space compatible with gymnasiam and whichever stable baselines function we use.\n",
        "\n",
        "        # Note: I haven't testing this code yet, as the PPO function I used allowed me to take in a Dict as the observation space, and hence i did nt need to change the type of the observation space.\n",
        "\n",
        "        # see the link mentioned above in my comment to see more information about this code and more code about changing the observation space.\n",
        "\n",
        "\n",
        "        self._gym_env.observation_space.close()\n",
        "        # self._gym_env.observation_space = BoxGymObsSpace(self._g2op_env.observation_space, attr_to_keep=obs_attr_to_keep)\n",
        "        self._gym_env.observation_space = BoxGymObsSpace(self._g2op_env.observation_space, attr_to_keep = attr_to_keep)\n",
        "        #print(\"WARNING: setup_observations is not doing anything. Implement your own code in this method.\")\n",
        "\n",
        "    def setup_actions(self):\n",
        "        # TODO: Your code to specify & modify the action space goes here\n",
        "        # See Grid2Op 'getting started' notebooks for guidance\n",
        "        #  - Notebooks: https://github.com/rte-france/Grid2Op/tree/master/getting_started\n",
        "\n",
        "        self._gym_env.action_space = DiscreteActSpace(self._g2op_env.action_space, attr_to_keep=[\"set_bus\" , \"set_line_status_simple\"])\n",
        "        #self._gym_env.action_space = DiscreteActSpace(self._g2op_env.action_space)\n",
        "\n",
        "        #print(\"WARNING: setup_actions is not doing anything. Implement your own code in this method.\")\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        return self._gym_env.reset(seed=seed, options=None)\n",
        "\n",
        "    def step(self, action):\n",
        "        return self._gym_env.step(action)\n",
        "\n",
        "    def render(self):\n",
        "        # TODO: Modify for your own required usage\n",
        "        return self._gym_env.render()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Random agent interacting in environment #\n",
        "\n",
        "    max_steps = 100\n",
        "\n",
        "    env = Gym2OpEnv(attr_to_keep)\n",
        "\n",
        "    print(\"#####################\")\n",
        "    print(\"# OBSERVATION SPACE #\")\n",
        "    print(\"#####################\")\n",
        "    print(env.observation_space)\n",
        "    print(\"#####################\\n\")\n",
        "\n",
        "    print(\"#####################\")\n",
        "    print(\"#   ACTION SPACE    #\")\n",
        "    print(\"#####################\")\n",
        "    print(env.action_space)\n",
        "    print(\"#####################\\n\\n\")\n",
        "\n",
        "    curr_step = 0\n",
        "    curr_return = 0\n",
        "\n",
        "    is_done = False\n",
        "    obs, info = env.reset()\n",
        "    print(f\"step = {curr_step} (reset):\")\n",
        "    print(f\"\\t obs = {obs}\")\n",
        "    print(f\"\\t info = {info}\\n\\n\")\n",
        "\n",
        "    while not is_done and curr_step < max_steps:\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        curr_step += 1\n",
        "        curr_return += reward\n",
        "        is_done = terminated or truncated\n",
        "\n",
        "        print(f\"step = {curr_step}: \")\n",
        "        print(f\"\\t obs = {obs}\")\n",
        "        print(f\"\\t reward = {reward}\")\n",
        "        print(f\"\\t terminated = {terminated}\")\n",
        "        print(f\"\\t truncated = {truncated}\")\n",
        "        print(f\"\\t info = {info}\")\n",
        "\n",
        "        # Some actions are invalid (see: https://grid2op.readthedocs.io/en/latest/action.html#illegal-vs-ambiguous)\n",
        "        # Invalid actions are replaced with 'do nothing' action\n",
        "        is_action_valid = not (info[\"is_illegal\"] or info[\"is_ambiguous\"])\n",
        "        print(f\"\\t is action valid = {is_action_valid}\")\n",
        "        if not is_action_valid:\n",
        "            print(f\"\\t\\t reason = {info['exception']}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"###########\")\n",
        "    print(\"# SUMMARY #\")\n",
        "    print(\"###########\")\n",
        "    print(f\"return = {curr_return}\")\n",
        "    print(f\"total steps = {curr_step}\")\n",
        "    print(\"###########\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hoXYJBJ6eLt",
        "outputId": "cb3cb777-3d17-40ce-a8b5-8a665c30af15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/grid2op/MakeEnv/Make.py:506: UserWarning: It is the first time you use the environment \"l2rpn_case14_sandbox\".\n",
            "We will attempt to download this environment from remote\n",
            "  warnings.warn(_MAKE_FIRST_TIME_WARN.format(dataset_name))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading the training data, this may take a while.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "l2rpn_case14_sandbox.tar.bz2: 294MB [00:31, 9.31MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract the tar archive in \"/root/data_grid2op\"\n",
            "\t Successfully updated file \"config.py\" for environment \"l2rpn_case14_sandbox\"\n",
            "\t Successfully updated file \"grid.json\" for environment \"l2rpn_case14_sandbox\"\n",
            "You may now use the environment \"l2rpn_case14_sandbox\" with the available data by invoking:\n",
            "\tenv = grid2op.make(\"l2rpn_case14_sandbox\")\n",
            "#####################\n",
            "# OBSERVATION SPACE #\n",
            "#####################\n",
            "Box([-140.   -120.    -70.    -70.    -40.   -100.   -162.01 -162.01 -162.01\n",
            " -162.01 -162.01 -162.01    -inf    -inf    -inf    -inf    -inf    -inf\n",
            "    -inf    -inf    -inf    -inf    -inf    0.      0.      0.      0.\n",
            "    0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
            "    0.      0.      0.      0.      0.      0.      0.     -1.     -1.\n",
            "   -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.\n",
            "   -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.\n",
            "   -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.\n",
            "   -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.\n",
            "   -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.\n",
            "   -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.     -1.\n",
            "   -1.  ], [140.      120.       70.       70.       40.      100.      302.01\n",
            " 282.01    232.01001 232.01001 202.01    262.01          inf       inf\n",
            "       inf       inf       inf       inf       inf       inf       inf\n",
            "       inf       inf       inf       inf       inf       inf       inf\n",
            "       inf       inf       inf       inf       inf       inf       inf\n",
            "       inf       inf       inf       inf       inf       inf       inf\n",
            "       inf   2.        2.        2.        2.        2.        2.\n",
            "   2.        2.        2.        2.        2.        2.        2.\n",
            "   2.        2.        2.        2.        2.        2.        2.\n",
            "   2.        2.        2.        2.        2.        2.        2.\n",
            "   2.        2.        2.        2.        2.        2.        2.\n",
            "   2.        2.        2.        2.        2.        2.        2.\n",
            "   2.        2.        2.        2.        2.        2.        2.\n",
            "   2.        2.        2.        2.        2.        2.        2.\n",
            "   2.        2.     ], (100,), float32)\n",
            "#####################\n",
            "\n",
            "#####################\n",
            "#   ACTION SPACE    #\n",
            "#####################\n",
            "Discrete(219)\n",
            "#####################\n",
            "\n",
            "\n",
            "step = 0 (reset):\n",
            "\t obs = [ 0.          0.          0.          0.          0.          0.\n",
            " 80.8        79.          3.2         0.          0.         81.34898\n",
            " 21.8        84.8        43.4         6.8        11.6        27.8\n",
            "  8.6         3.4         5.4        12.4        14.2         0.3354469\n",
            "  0.35771054  0.26622066  0.26474696  0.8243342   0.2712033   0.33215174\n",
            "  0.5168022   0.48678526  0.7146054   0.30842003  0.38281375  0.28180888\n",
            "  0.4164844   0.38181946  0.5445216   0.53200793  0.9379576   0.44847175\n",
            "  0.45735082  1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.        ]\n",
            "\t info = {'time serie id': '/root/data_grid2op/l2rpn_case14_sandbox/chronics/0718'}\n",
            "\n",
            "\n",
            "step = 1: \n",
            "\t obs = [ 0.          0.          0.          0.          0.          0.\n",
            " 81.3        79.7         3.2         0.          0.         79.256065\n",
            " 21.7        83.9        43.6         6.7        11.4        27.2\n",
            "  8.7         3.4         5.4        12.3        14.6         0.3163632\n",
            "  0.36071867  0.2491363   0.25466964  0.8556174   0.27314448  0.18583475\n",
            "  0.8058622   0.5394731   0.8451035   0.27882174  0.18517959  0.49595526\n",
            "  0.5838216   0.57551265  0.34480038  0.9571678   1.2552222   0.39332023\n",
            "  0.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          2.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.        ]\n",
            "\t reward = 0.26037874817848206\n",
            "\t terminated = False\n",
            "\t truncated = False\n",
            "\t info = {'disc_lines': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "       -1, -1, -1], dtype=int32), 'is_illegal': False, 'is_ambiguous': False, 'is_dispatching_illegal': False, 'is_illegal_reco': False, 'reason_alarm_illegal': None, 'reason_alert_illegal': None, 'opponent_attack_line': None, 'opponent_attack_sub': None, 'opponent_attack_duration': 0, 'exception': [], 'time_series_id': '/root/data_grid2op/l2rpn_case14_sandbox/chronics/0718', 'rewards': {}}\n",
            "\t is action valid = True\n",
            "\n",
            "\n",
            "step = 2: \n",
            "\t obs = [ 0.          0.          0.          0.          0.          0.\n",
            " 82.7        80.8         3.2         0.          0.         77.65499\n",
            " 21.7        83.6        44.7         6.8        11.6        27.1\n",
            "  8.7         3.4         5.5        12.4        14.3         0.30516234\n",
            "  0.35918248  0.24301642  0.2563564   0.8623265   0.28370073  0.18559198\n",
            "  0.8066998   0.541599    0.8460049   0.28102955  0.17856306  0.49664223\n",
            "  0.5843788   0.57142216  0.34648898  0.95391905  1.2580793   0.39524642\n",
            "  0.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          2.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.          1.          1.\n",
            "  1.          1.          1.          1.        ]\n",
            "\t reward = 0.2602633833885193\n",
            "\t terminated = False\n",
            "\t truncated = False\n",
            "\t info = {'disc_lines': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "       -1, -1, -1], dtype=int32), 'is_illegal': False, 'is_ambiguous': False, 'is_dispatching_illegal': False, 'is_illegal_reco': False, 'reason_alarm_illegal': None, 'reason_alert_illegal': None, 'opponent_attack_line': None, 'opponent_attack_sub': None, 'opponent_attack_duration': 0, 'exception': [], 'time_series_id': '/root/data_grid2op/l2rpn_case14_sandbox/chronics/0718', 'rewards': {}}\n",
            "\t is action valid = True\n",
            "\n",
            "\n",
            "step = 3: \n",
            "\t obs = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
            "\t reward = -0.5\n",
            "\t terminated = True\n",
            "\t truncated = False\n",
            "\t info = {'disc_lines': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,\n",
            "        0, -1, -1], dtype=int32), 'is_illegal': False, 'is_ambiguous': False, 'is_dispatching_illegal': False, 'is_illegal_reco': False, 'reason_alarm_illegal': None, 'reason_alert_illegal': None, 'opponent_attack_line': None, 'opponent_attack_sub': None, 'opponent_attack_duration': 0, 'exception': ['Grid2OpException BackendError \"Divergence of DC powerflow (non connected grid) at the initialization of AC powerflow. Detailed error: ErrorType.SolverSolve\"'], 'time_series_id': '/root/data_grid2op/l2rpn_case14_sandbox/chronics/0718', 'rewards': {}}\n",
            "\t is action valid = True\n",
            "\n",
            "\n",
            "###########\n",
            "# SUMMARY #\n",
            "###########\n",
            "return = 0.020642131567001343\n",
            "total steps = 3\n",
            "###########\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "# Custom Action Tracker Callback\n",
        "class ActionTrackerCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super(ActionTrackerCallback, self).__init__(verbose)\n",
        "        self.action_counter = defaultdict(int)\n",
        "\n",
        "    def _on_step(self):\n",
        "        # Track the actions taken during training\n",
        "        action = self.locals['actions']\n",
        "        if isinstance(action, np.ndarray):\n",
        "            action_key = tuple(action)\n",
        "        else:\n",
        "            action_key = (action,)\n",
        "        self.action_counter[action_key] += 1\n",
        "        return True\n",
        "\n",
        "    def _on_training_end(self):\n",
        "        # Called at the end of training - print action distribution here\n",
        "        print(\"Training completed! Action distribution:\")\n",
        "        for action, freq in sorted(self.action_counter.items(), key=lambda x: x[1], reverse=True):\n",
        "            print(f\"Action: {action}, Frequency: {freq}\")\n",
        "\n",
        "    def get_action_distribution(self):\n",
        "        return dict(self.action_counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2j8DhHP6g5a",
        "outputId": "d6754d52-0fa8-4d79-a005-80a0dd9ed92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
            "  from jax import xla_computation as _xla_computation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, env, num_episodes=10):\n",
        "    all_episode_rewards = []\n",
        "    all_episode_lengths = []\n",
        "    all_n1_rewards = []\n",
        "    all_l2rpn_rewards = []\n",
        "\n",
        "    for _ in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "        episode_length = 0\n",
        "        n1_reward = 0\n",
        "        l2rpn_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, _, info = env.step(action)\n",
        "            episode_reward += reward\n",
        "            episode_length += 1\n",
        "\n",
        "            # Extract individual rewards\n",
        "            n1_reward += info.get('rewards', {}).get('N1', 0)\n",
        "            l2rpn_reward += info.get('rewards', {}).get('L2RPN', 0)\n",
        "\n",
        "        all_episode_rewards.append(episode_reward)\n",
        "        all_episode_lengths.append(episode_length)\n",
        "        all_n1_rewards.append(n1_reward)\n",
        "        all_l2rpn_rewards.append(l2rpn_reward)\n",
        "\n",
        "    mean_reward = np.mean(all_episode_rewards)\n",
        "    std_reward = np.std(all_episode_rewards)\n",
        "    mean_length = np.mean(all_episode_lengths)\n",
        "    std_length = np.std(all_episode_lengths)\n",
        "    mean_n1 = np.mean(all_n1_rewards)\n",
        "    std_n1 = np.std(all_n1_rewards)\n",
        "    mean_l2rpn = np.mean(all_l2rpn_rewards)\n",
        "    std_l2rpn = np.std(all_l2rpn_rewards)\n",
        "\n",
        "    return mean_reward, std_reward, mean_length, std_length, mean_n1, std_n1, mean_l2rpn, std_l2rpn"
      ],
      "metadata": {
        "id": "NtyfQxrUbanF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import grid2op\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import wandb\n",
        "import sys\n",
        "sys.path.insert(0,\"./\") # this makes it possible to import the wrapper since the env.py is in it's own folder\n",
        "#from provided_wrapper.env import Gym2OpEnv\n",
        "from stable_baselines3 import DQN\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from sb3_contrib import QRDQN\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Initialize environment and monitor\n",
        "    env = Gym2OpEnv(attr_to_keep_3)\n",
        "    env = Monitor(env)\n",
        "\n",
        "    # Initialize Wandb\n",
        "    run = wandb.init(\n",
        "        project=\"RL_project\",\n",
        "        name=\"DQN improvement 2 qr-dqn\",\n",
        "        sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "        monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "        save_code=False,  # optional\n",
        "    )\n",
        "\n",
        "    # Initialize DQN model\n",
        "    # model = DQN(\"MlpPolicy\", env, verbose=1, device = device, tensorboard_log=\"./dqn_grid2op_tensorboard/\")\n",
        "    policy_kwargs = dict(n_quantiles=50)\n",
        "    model2 = QRDQN(\"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
        "\n",
        "\n",
        "    # Initialize custom callback to track actions\n",
        "    action_callback = ActionTrackerCallback()\n",
        "\n",
        "    # Training the model with Wandb and custom action tracking callback\n",
        "    model2.learn(\n",
        "        total_timesteps=1000000,\n",
        "        log_interval=10,\n",
        "        callback=[WandbCallback(gradient_save_freq=100, model_save_path=f\"models/{run.id}\", verbose=1), action_callback],\n",
        "        progress_bar=True\n",
        "    )\n",
        "\n",
        "    # After training, print the action distribution\n",
        "    action_distribution = action_callback.get_action_distribution()\n",
        "\n",
        "    print(\"\\nFinal Action Distribution:\")\n",
        "    for action, freq in sorted(action_distribution.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"Action: {action}, Frequency: {freq}\")\n",
        "\n",
        "\n",
        "    #Evaluating the trained model\n",
        "    print(\"\\nEvaluating the trained model\")\n",
        "    mean_reward, std_reward, mean_length, std_length, mean_n1, std_n1, mean_l2rpn, std_l2rpn = evaluate_model(model, env, num_episodes=50)\n",
        "    wandb.log({\n",
        "        \"eval/mean_total_reward\": mean_reward,\n",
        "        \"eval/std_total_reward\": std_reward,\n",
        "        \"eval/mean_episode_length\": mean_length,\n",
        "        \"eval/std_episode_length\": std_length,\n",
        "        \"eval/mean_N1_reward\": mean_n1,\n",
        "        \"eval/std_N1_reward\": std_n1,\n",
        "        \"eval/mean_L2RPN_reward\": mean_l2rpn,\n",
        "        \"eval/std_L2RPN_reward\": std_l2rpn\n",
        "    })\n",
        "\n",
        "    print(f\"\\nEvaluation Results:\")\n",
        "    print(f\"Mean Total Reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "    print(f\"Mean Episode Length: {mean_length:.2f} +/- {std_length:.2f}\")\n",
        "    print(f\"Mean N1 Reward: {mean_n1:.2f} +/- {std_n1:.2f}\")\n",
        "    print(f\"Mean L2RPN Reward: {mean_l2rpn:.2f} +/- {std_l2rpn:.2f}\")\n",
        "    run.finish()\n",
        "\n",
        "    # # Test the trained model\n",
        "    # obs, _ = env.reset()  # Get initial observation and info\n",
        "    # for _ in range(1000):\n",
        "    #     # Predict action using only the observation part of the returned tuple\n",
        "    #     action, _states = model.predict(obs, deterministic=True)\n",
        "    #     obs, reward, done, _, info = env.step(action)\n",
        "    #     env.render()\n",
        "    #     if done:\n",
        "    #         obs, _ = env.reset()  # Reset environment if done, and unpack the tuple again\n",
        "\n",
        "    env.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-bO1YBJ66j2G",
        "outputId": "b75a3609-eeec-4ef3-a4a6-6ec7b24880bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m999,994/1,000,000 \u001b[0m [ \u001b[33m3:06:53\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m106 it/s\u001b[0m ]\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">999,994/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">3:06:53</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">106 it/s</span> ]\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (180,), Frequency: 459\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (180,), Frequency: 459\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (158,), Frequency: 458\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (158,), Frequency: 458\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (58,), Frequency: 456\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (58,), Frequency: 456\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (139,), Frequency: 456\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (139,), Frequency: 456\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (187,), Frequency: 456\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (187,), Frequency: 456\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (155,), Frequency: 455\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (155,), Frequency: 455\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (179,), Frequency: 454\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (179,), Frequency: 454\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (113,), Frequency: 453\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (113,), Frequency: 453\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (105,), Frequency: 453\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (105,), Frequency: 453\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (96,), Frequency: 452\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (96,), Frequency: 452\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (157,), Frequency: 449\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (157,), Frequency: 449\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (44,), Frequency: 448\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (44,), Frequency: 448\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (92,), Frequency: 446\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (92,), Frequency: 446\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (13,), Frequency: 446\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (13,), Frequency: 446\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (43,), Frequency: 446\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (43,), Frequency: 446\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (182,), Frequency: 445\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (182,), Frequency: 445\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (35,), Frequency: 444\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (35,), Frequency: 444\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (110,), Frequency: 443\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (110,), Frequency: 443\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (126,), Frequency: 442\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (126,), Frequency: 442\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (197,), Frequency: 441\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (197,), Frequency: 441\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (112,), Frequency: 440\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (112,), Frequency: 440\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (52,), Frequency: 439\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (52,), Frequency: 439\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (26,), Frequency: 438\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (26,), Frequency: 438\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (29,), Frequency: 438\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (29,), Frequency: 438\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (114,), Frequency: 437\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (114,), Frequency: 437\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (128,), Frequency: 437\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (128,), Frequency: 437\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (25,), Frequency: 432\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (25,), Frequency: 432\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (60,), Frequency: 432\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (60,), Frequency: 432\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (116,), Frequency: 431\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (116,), Frequency: 431\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (186,), Frequency: 420\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (186,), Frequency: 420\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (194,), Frequency: 420\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (194,), Frequency: 420\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (14,), Frequency: 420\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (14,), Frequency: 420\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (30,), Frequency: 419\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (30,), Frequency: 419\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (143,), Frequency: 418\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (143,), Frequency: 418\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (107,), Frequency: 417\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (107,), Frequency: 417\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (188,), Frequency: 417\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (188,), Frequency: 417\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (151,), Frequency: 415\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (151,), Frequency: 415\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (173,), Frequency: 411\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (173,), Frequency: 411\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Action: (42,), Frequency: 388\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Action: (42,), Frequency: 388\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Action Distribution:\n",
            "Action: (136,), Frequency: 29871\n",
            "Action: (4,), Frequency: 20415\n",
            "Action: (5,), Frequency: 18618\n",
            "Action: (84,), Frequency: 15055\n",
            "Action: (172,), Frequency: 14847\n",
            "Action: (192,), Frequency: 14539\n",
            "Action: (76,), Frequency: 13302\n",
            "Action: (39,), Frequency: 12846\n",
            "Action: (38,), Frequency: 11772\n",
            "Action: (162,), Frequency: 10997\n",
            "Action: (77,), Frequency: 10867\n",
            "Action: (87,), Frequency: 10726\n",
            "Action: (135,), Frequency: 10723\n",
            "Action: (138,), Frequency: 10006\n",
            "Action: (148,), Frequency: 9761\n",
            "Action: (67,), Frequency: 9720\n",
            "Action: (88,), Frequency: 9617\n",
            "Action: (55,), Frequency: 9561\n",
            "Action: (183,), Frequency: 9324\n",
            "Action: (145,), Frequency: 9188\n",
            "Action: (24,), Frequency: 9183\n",
            "Action: (12,), Frequency: 9151\n",
            "Action: (199,), Frequency: 9118\n",
            "Action: (97,), Frequency: 9078\n",
            "Action: (213,), Frequency: 8994\n",
            "Action: (65,), Frequency: 8984\n",
            "Action: (21,), Frequency: 8953\n",
            "Action: (98,), Frequency: 8944\n",
            "Action: (214,), Frequency: 8838\n",
            "Action: (85,), Frequency: 8765\n",
            "Action: (63,), Frequency: 8655\n",
            "Action: (53,), Frequency: 8645\n",
            "Action: (80,), Frequency: 8559\n",
            "Action: (62,), Frequency: 8544\n",
            "Action: (207,), Frequency: 8242\n",
            "Action: (210,), Frequency: 8116\n",
            "Action: (33,), Frequency: 8034\n",
            "Action: (176,), Frequency: 7986\n",
            "Action: (47,), Frequency: 7963\n",
            "Action: (185,), Frequency: 7936\n",
            "Action: (129,), Frequency: 7917\n",
            "Action: (1,), Frequency: 7813\n",
            "Action: (69,), Frequency: 7794\n",
            "Action: (195,), Frequency: 7775\n",
            "Action: (208,), Frequency: 7751\n",
            "Action: (163,), Frequency: 7744\n",
            "Action: (104,), Frequency: 7693\n",
            "Action: (184,), Frequency: 7677\n",
            "Action: (0,), Frequency: 7445\n",
            "Action: (174,), Frequency: 7436\n",
            "Action: (140,), Frequency: 7427\n",
            "Action: (217,), Frequency: 7385\n",
            "Action: (203,), Frequency: 7319\n",
            "Action: (11,), Frequency: 7275\n",
            "Action: (200,), Frequency: 7240\n",
            "Action: (177,), Frequency: 7231\n",
            "Action: (160,), Frequency: 7132\n",
            "Action: (144,), Frequency: 7094\n",
            "Action: (193,), Frequency: 7086\n",
            "Action: (201,), Frequency: 7064\n",
            "Action: (141,), Frequency: 7035\n",
            "Action: (211,), Frequency: 7008\n",
            "Action: (166,), Frequency: 6954\n",
            "Action: (215,), Frequency: 6881\n",
            "Action: (209,), Frequency: 6851\n",
            "Action: (218,), Frequency: 6653\n",
            "Action: (205,), Frequency: 6631\n",
            "Action: (178,), Frequency: 6624\n",
            "Action: (204,), Frequency: 6512\n",
            "Action: (216,), Frequency: 6484\n",
            "Action: (170,), Frequency: 6484\n",
            "Action: (202,), Frequency: 6458\n",
            "Action: (34,), Frequency: 6446\n",
            "Action: (103,), Frequency: 6409\n",
            "Action: (37,), Frequency: 6375\n",
            "Action: (78,), Frequency: 6323\n",
            "Action: (79,), Frequency: 6315\n",
            "Action: (49,), Frequency: 6273\n",
            "Action: (206,), Frequency: 6203\n",
            "Action: (16,), Frequency: 6139\n",
            "Action: (120,), Frequency: 6130\n",
            "Action: (117,), Frequency: 6105\n",
            "Action: (212,), Frequency: 6052\n",
            "Action: (169,), Frequency: 5957\n",
            "Action: (156,), Frequency: 5914\n",
            "Action: (15,), Frequency: 5869\n",
            "Action: (119,), Frequency: 5760\n",
            "Action: (81,), Frequency: 5617\n",
            "Action: (118,), Frequency: 5581\n",
            "Action: (45,), Frequency: 5511\n",
            "Action: (130,), Frequency: 5437\n",
            "Action: (106,), Frequency: 5391\n",
            "Action: (101,), Frequency: 5141\n",
            "Action: (64,), Frequency: 4989\n",
            "Action: (57,), Frequency: 4941\n",
            "Action: (132,), Frequency: 4822\n",
            "Action: (164,), Frequency: 4798\n",
            "Action: (147,), Frequency: 4744\n",
            "Action: (165,), Frequency: 4626\n",
            "Action: (27,), Frequency: 4598\n",
            "Action: (72,), Frequency: 4333\n",
            "Action: (86,), Frequency: 4270\n",
            "Action: (167,), Frequency: 4244\n",
            "Action: (161,), Frequency: 4197\n",
            "Action: (51,), Frequency: 4186\n",
            "Action: (31,), Frequency: 4045\n",
            "Action: (46,), Frequency: 3767\n",
            "Action: (133,), Frequency: 3748\n",
            "Action: (17,), Frequency: 3675\n",
            "Action: (70,), Frequency: 3620\n",
            "Action: (196,), Frequency: 3620\n",
            "Action: (82,), Frequency: 3561\n",
            "Action: (102,), Frequency: 3520\n",
            "Action: (191,), Frequency: 3452\n",
            "Action: (74,), Frequency: 3425\n",
            "Action: (181,), Frequency: 3361\n",
            "Action: (20,), Frequency: 3359\n",
            "Action: (28,), Frequency: 3338\n",
            "Action: (23,), Frequency: 3186\n",
            "Action: (2,), Frequency: 3185\n",
            "Action: (131,), Frequency: 3150\n",
            "Action: (61,), Frequency: 3115\n",
            "Action: (134,), Frequency: 2961\n",
            "Action: (137,), Frequency: 2853\n",
            "Action: (6,), Frequency: 2845\n",
            "Action: (3,), Frequency: 2731\n",
            "Action: (48,), Frequency: 2725\n",
            "Action: (100,), Frequency: 2654\n",
            "Action: (54,), Frequency: 2596\n",
            "Action: (83,), Frequency: 2552\n",
            "Action: (71,), Frequency: 2538\n",
            "Action: (66,), Frequency: 2469\n",
            "Action: (73,), Frequency: 2418\n",
            "Action: (22,), Frequency: 2378\n",
            "Action: (32,), Frequency: 2328\n",
            "Action: (75,), Frequency: 2312\n",
            "Action: (99,), Frequency: 2185\n",
            "Action: (50,), Frequency: 2156\n",
            "Action: (56,), Frequency: 2155\n",
            "Action: (122,), Frequency: 2044\n",
            "Action: (152,), Frequency: 2016\n",
            "Action: (59,), Frequency: 1941\n",
            "Action: (41,), Frequency: 1866\n",
            "Action: (190,), Frequency: 1766\n",
            "Action: (124,), Frequency: 1749\n",
            "Action: (19,), Frequency: 1721\n",
            "Action: (8,), Frequency: 1697\n",
            "Action: (154,), Frequency: 1613\n",
            "Action: (90,), Frequency: 1368\n",
            "Action: (108,), Frequency: 1342\n",
            "Action: (68,), Frequency: 1214\n",
            "Action: (121,), Frequency: 1205\n",
            "Action: (142,), Frequency: 1072\n",
            "Action: (175,), Frequency: 859\n",
            "Action: (93,), Frequency: 736\n",
            "Action: (95,), Frequency: 670\n",
            "Action: (168,), Frequency: 666\n",
            "Action: (146,), Frequency: 615\n",
            "Action: (111,), Frequency: 614\n",
            "Action: (7,), Frequency: 534\n",
            "Action: (149,), Frequency: 526\n",
            "Action: (109,), Frequency: 499\n",
            "Action: (189,), Frequency: 494\n",
            "Action: (127,), Frequency: 493\n",
            "Action: (159,), Frequency: 490\n",
            "Action: (115,), Frequency: 488\n",
            "Action: (171,), Frequency: 487\n",
            "Action: (40,), Frequency: 480\n",
            "Action: (94,), Frequency: 480\n",
            "Action: (125,), Frequency: 477\n",
            "Action: (36,), Frequency: 477\n",
            "Action: (89,), Frequency: 476\n",
            "Action: (150,), Frequency: 475\n",
            "Action: (18,), Frequency: 473\n",
            "Action: (198,), Frequency: 472\n",
            "Action: (153,), Frequency: 471\n",
            "Action: (9,), Frequency: 470\n",
            "Action: (91,), Frequency: 469\n",
            "Action: (123,), Frequency: 465\n",
            "Action: (10,), Frequency: 464\n",
            "Action: (180,), Frequency: 459\n",
            "Action: (158,), Frequency: 458\n",
            "Action: (58,), Frequency: 456\n",
            "Action: (139,), Frequency: 456\n",
            "Action: (187,), Frequency: 456\n",
            "Action: (155,), Frequency: 455\n",
            "Action: (179,), Frequency: 454\n",
            "Action: (113,), Frequency: 453\n",
            "Action: (105,), Frequency: 453\n",
            "Action: (96,), Frequency: 452\n",
            "Action: (157,), Frequency: 449\n",
            "Action: (44,), Frequency: 448\n",
            "Action: (92,), Frequency: 446\n",
            "Action: (13,), Frequency: 446\n",
            "Action: (43,), Frequency: 446\n",
            "Action: (182,), Frequency: 445\n",
            "Action: (35,), Frequency: 444\n",
            "Action: (110,), Frequency: 443\n",
            "Action: (126,), Frequency: 442\n",
            "Action: (197,), Frequency: 441\n",
            "Action: (112,), Frequency: 440\n",
            "Action: (52,), Frequency: 439\n",
            "Action: (26,), Frequency: 438\n",
            "Action: (29,), Frequency: 438\n",
            "Action: (114,), Frequency: 437\n",
            "Action: (128,), Frequency: 437\n",
            "Action: (25,), Frequency: 432\n",
            "Action: (60,), Frequency: 432\n",
            "Action: (116,), Frequency: 431\n",
            "Action: (186,), Frequency: 420\n",
            "Action: (194,), Frequency: 420\n",
            "Action: (14,), Frequency: 420\n",
            "Action: (30,), Frequency: 419\n",
            "Action: (143,), Frequency: 418\n",
            "Action: (107,), Frequency: 417\n",
            "Action: (188,), Frequency: 417\n",
            "Action: (151,), Frequency: 415\n",
            "Action: (173,), Frequency: 411\n",
            "Action: (42,), Frequency: 388\n",
            "\n",
            "Evaluating the trained model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'evaluate_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1f9738a01a84>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-1f9738a01a84>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m#Evaluating the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEvaluating the trained model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mmean_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_n1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_n1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_l2rpn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_l2rpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     wandb.log({\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m\"eval/mean_total_reward\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmean_reward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
          ]
        }
      ]
    }
  ]
}